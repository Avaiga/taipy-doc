---
title: LLM ChatBot
category: llm
data-keywords: vizelement ai community
short-description: Leverage this chatbot using OpenAI's API with GPT-4 to use it as a template for an LLM inference application.
order: 8
img: chatbot/images/chatbot_meds_conv.png
hide:
    - toc
---
This demo showcases Taipy's ability to enable end-users to run inference using LLMs. Here, we
use GPT-4 to create a chatbot and display the conversation in an interactive chat interface.

[Try it live](https://demo-llm-chat.taipy.cloud/){: .tp-btn target='blank' }
[Get it on GitHub](https://github.com/Avaiga/demo-llm-chat){: .tp-btn .tp-btn--accent target='blank' }

# Understanding the Application

This application allows the user to chat with GPT-4 by sending
its input to the OpenAI API and returning the conversation in
a chat window. The user can also return to a previous
conversation and continue it.

![ChatBot](images/chatbot_meds_conv.png){width=100% : .tp-image-border }

A tutorial on how to write this application and similar
LLM inference applications is available [here](../../../tutorials/articles/chatbot/index.md).
