# Data node attributes

The data node creation method returns a `DataNode^` entity.
It is
identified by
a unique identifier named `id` that is generated by Taipy.
A data node also holds various properties and attributes that are accessible through the entity:

-   `config_id`: The id of the data node config.
-   `scope`: The scope of this data node (scenario, pipeline, etc).
-   `id`: The unique identifier of this data node.
-   `name`: The user-readable name if the data node.
-   `parent_id`: The identifier of the parent (pipeline_id, scenario_id, cycle_id) or `None`.
-   `last_edition_date`: The date and time of the last edition.
-   `job_ids`: The ordered list of jobs that have written on this data node.
-   `validity_days`: The number of days to be added to the data node validity duration.
-   `validity_hours`: The number of hours to be added to the data node validity duration.
-   `validity_minutes`: The number of minutes to be added to the data node validity duration.
-   `edition_in_progress`: The flag that signals if a task is currently computing this data node.
-   `properties`: The dict of additional arguments.

# Get data node

The first method to get a **data node** is from its id using the
`taipy.get()^` method:

!!! Example

    ```python linenums="1"
    import taipy as tp

    # Retrieve a data node by its id
    data_node = tp.get(data_node_id)
    ```

The data nodes that are part of a **scenario** or **pipeline** can be directly accessed on their levels:

!!! Example

    ```python linenums="1"
    import taipy as tp
    from config import *

    # Creating a scenario from a config
    scenario = tp.create_scenario(monthly_scenario_cfg)

    # Access the data node from a scenario
    scenario.sales_history

    # Access the pipeline from a scenario
    scenario.sales

    # Access the data node from a pipeline
    scenario.sales.sales_history
    ```

All the data nodes can be retrieved using the method
`taipy.get_data_nodes()^`. This method returns a list of
all existing data nodes.

!!! Example

    ```python linenums="1"
    import taipy as tp

    # Retrieve a data node by its id
    data_nodes = tp.get_data_nodes()

    data_nodes #[DataNode 1, DataNode 2, ..., DataNode N]
    ```

# Read data node

To read the content of a data node you can use the
`data_node.read()^`
method. The read method returns the data stored on the data node according to the type of data node:

!!! Example

    ```python linenums="1"
    import taipy as tp

    # Retrieve a data node by its id
    data_node = tp.get(data_node_id)

    # Returns the content stored on the data node
    data_node.read()
    ```

Is also possible to read partially the contents of data node, usefully when dealing with large amounts of data.
This can be achieved using the `data_node.filter^`
method:

```python linenums="1"
data_node.filter([('field_name_like_temperature', 14, Operator.EQUAL), ('field_name_like_temperature', 10, Operator.EQUAL)], JoinOperator.OR))
```

Is also possible to use pandas style filtering:

```python linenums="1"
temp_data = data_node['field_name_like_temperature']
temp_data[(temp_data == 14) | (temp_data == 10)]
```

# Write data node

To write some data on the data node, like the output of a task, you can use the
`data_node.write^` method.
The method takes an data object (string, dictionary, lists, numpy arrays, pandas dataframes, etc) as a
parameter and writes it on the data node:

!!! Example

    ```python linenums="1"
    import taipy as tp

    # Retrieve a data node by its id
    data_node = tp.get(data_node_id)

    data = [{"a": "1", "b": "2"}, {"a": "3", "b": "4"}]

    # Writes the dictionary on the data node
    data_node.write(data)

    # returns the new data stored on the data node
    data_node.read()
    ```

[:material-arrow-right: Next section show the scheduling and job execution features](scheduling-and-job-execution.md).
